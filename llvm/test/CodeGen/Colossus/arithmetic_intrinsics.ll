; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --remove_checks
; RUN: llc < %s -mtriple=colossus -colossus-coissue=false -mattr=+ipu1 | FileCheck %s --check-prefixes=CHECK,IPU1_2
; RUN: llc < %s -mtriple=colossus -colossus-coissue=false -mattr=+ipu2 | FileCheck %s --check-prefixes=CHECK,IPU1_2

target triple = "colossus-graphcore--elf"

declare half @llvm.cos.f16(half %x)
define half @test_cos_f16(half %x) {
; CHECK-LABEL: test_cos_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_cos
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.cos.f16(half %x)
  ret half %res
}

declare half @llvm.experimental.constrained.cos.f16(half, metadata, metadata)
define half @test_constrained_cos_f16(half %x) {
; CHECK-LABEL: test_constrained_cos_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_cos
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.cos.f16(half %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

declare float @llvm.cos.f32(float %x)
define float @test_cos_f32(float %x) {
; CHECK-LABEL: test_cos_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, cosf
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.cos.f32(float %x)
  ret float %res
}

declare float @llvm.experimental.constrained.cos.f32(float, metadata, metadata)
define float @test_constrained_cos_f32(float %x) {
; CHECK-LABEL: test_constrained_cos_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, cosf
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.cos.f32(float %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

declare <2 x half> @llvm.cos.v2f16(<2 x half> %x)
define <2 x half> @test_cos_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_cos_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half2_cos
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.cos.v2f16(<2 x half> %x)
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.cos.v2f16(<2 x half>, metadata, metadata)
define <2 x half> @test_constrained_cos_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_constrained_cos_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half2_cos
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.cos.v2f16(<2 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

declare <2 x float> @llvm.cos.v2f32(<2 x float> %x)
define <2 x float> @test_cos_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_cos_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_cos
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.cos.v2f32(<2 x float> %x)
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.cos.v2f32(<2 x float>, metadata, metadata)
define <2 x float> @test_constrained_cos_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_constrained_cos_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_cos
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.cos.v2f32(<2 x float> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

declare <4 x half> @llvm.cos.v4f16(<4 x half> %x)
define <4 x half> @test_cos_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_cos_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_cos
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.cos.v4f16(<4 x half> %x)
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.cos.v4f16(<4 x half>, metadata, metadata)
define <4 x half> @test_constrained_cos_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_constrained_cos_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_cos
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.cos.v4f16(<4 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

define half @test_div_f16(half %x, half %y) {
; CHECK-LABEL: test_div_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16tof32 $a1, $a1
; CHECK-NEXT:    f16tof32 $a0, $a0
; CHECK-NEXT:    f32div $a0, $a0, $a1
; CHECK-NEXT:    f32tof16 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = fdiv half %x, %y
  ret half %res
}

declare half @llvm.experimental.constrained.fdiv.f16(half, half, metadata, metadata)
define half @test_strict_div_f16(half %x, half %y) {
; CHECK-LABEL: test_strict_div_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16tof32 $a1, $a1
; CHECK-NEXT:    f16tof32 $a0, $a0
; CHECK-NEXT:    f32div $a0, $a0, $a1
; CHECK-NEXT:    f32tof16 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.fdiv.f16(half %x, half %y, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

define float @test_div_f32(float %x, float %y) {
; CHECK-LABEL: test_div_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32div $a0, $a0, $a1
; CHECK-NEXT:    br $m10
  %res = fdiv float %x, %y
  ret float %res
}

declare float @llvm.experimental.constrained.fdiv.f32(float, float, metadata, metadata)
define float @test_strict_div_f32(float %x, float %y) {
; CHECK-LABEL: test_strict_div_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32div $a0, $a0, $a1
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.fdiv.f32(float %x, float %y, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

define <2 x half> @test_div_v2f16(<2 x half> %x, <2 x half> %y) {
; CHECK-LABEL: test_div_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2tof32 $a2:3, $a1
; CHECK-NEXT:    f16v2tof32 $a0:1, $a0
; CHECK-NEXT:    f32div $a1, $a1, $a3
; CHECK-NEXT:    f32div $a0, $a0, $a2
; CHECK-NEXT:    f32v2tof16 $a0, $a0:1
; CHECK-NEXT:    br $m10
  %res = fdiv <2 x half> %x, %y
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.fdiv.v2f16(<2 x half>, <2 x half>, metadata, metadata)
define <2 x half> @test_strict_div_v2f16(<2 x half> %x, <2 x half> %y) {
; CHECK-LABEL: test_strict_div_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2tof32 $a2:3, $a1
; CHECK-NEXT:    f16v2tof32 $a0:1, $a0
; CHECK-NEXT:    f32div $a1, $a1, $a3
; CHECK-NEXT:    f32div $a0, $a0, $a2
; CHECK-NEXT:    f32v2tof16 $a0, $a0:1
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.fdiv.v2f16(<2 x half> %x, <2 x half> %y, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

define <2 x float> @test_div_v2f32(<2 x float> %x, <2 x float> %y) {
; CHECK-LABEL: test_div_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32div $a1, $a1, $a3
; CHECK-NEXT:    f32div $a0, $a0, $a2
; CHECK-NEXT:    br $m10
  %res = fdiv <2 x float> %x, %y
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.fdiv.v2f32(<2 x float>, <2 x float>, metadata, metadata)
define <2 x float> @test_strict_div_v2f32(<2 x float> %x, <2 x float> %y) {
; CHECK-LABEL: test_strict_div_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32div $a1, $a1, $a3
; CHECK-NEXT:    f32div $a0, $a0, $a2
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.fdiv.v2f32(<2 x float> %x, <2 x float> %y, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

define <4 x half> @test_div_v4f16(<4 x half> %x, <4 x half> %y) {
; IPU1_2-LABEL: test_div_v4f16:
; IPU1_2:       # %bb.0:
; IPU1_2-NEXT:    add $m11, $m11, -8
; IPU1_2-NEXT:    .cfi_def_cfa_offset 8
; IPU1_2-NEXT:    .cfi_offset $a6:7, -8
; IPU1_2-NEXT:    st64 $a6:7, $m11, $m15, 0 # 8-byte Folded Spill
; IPU1_2-NEXT:    mov $a4:5, $a0:1
; IPU1_2-NEXT:    f16v2tof32 $a6:7, $a2
; IPU1_2-NEXT:    f16v2tof32 $a2:3, $a3
; IPU1_2-NEXT:    f16v2tof32 $a0:1, $a4
; IPU1_2-NEXT:    f16v2tof32 $a4:5, $a5
; IPU1_2-NEXT:    f32div $a1, $a1, $a7
; IPU1_2-NEXT:    f32div $a0, $a0, $a6
; IPU1_2-NEXT:    f32v2tof16 $a0, $a0:1
; IPU1_2-NEXT:    f32div $a3, $a5, $a3
; IPU1_2-NEXT:    f32div $a2, $a4, $a2
; IPU1_2-NEXT:    f32v2tof16 $a1, $a2:3
; IPU1_2-NEXT:    ld64 $a6:7, $m11, $m15, 0 # 8-byte Folded Reload
; IPU1_2-NEXT:    add $m11, $m11, 8
; IPU1_2-NEXT:    .cfi_def_cfa_offset 0
; IPU1_2-NEXT:    br $m10
  %res = fdiv <4 x half> %x, %y
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.fdiv.v4f16(<4 x half>, <4 x half>, metadata, metadata)
define <4 x half> @test_strict_div_v4f16(<4 x half> %x, <4 x half> %y) {
; IPU1_2-LABEL: test_strict_div_v4f16:
; IPU1_2:       # %bb.0:
; IPU1_2-NEXT:    add $m11, $m11, -8
; IPU1_2-NEXT:    .cfi_def_cfa_offset 8
; IPU1_2-NEXT:    .cfi_offset $a6:7, -8
; IPU1_2-NEXT:    st64 $a6:7, $m11, $m15, 0 # 8-byte Folded Spill
; IPU1_2-NEXT:    mov $a4:5, $a0:1
; IPU1_2-NEXT:    f16v2tof32 $a6:7, $a2
; IPU1_2-NEXT:    f16v2tof32 $a2:3, $a3
; IPU1_2-NEXT:    f16v2tof32 $a0:1, $a4
; IPU1_2-NEXT:    f16v2tof32 $a4:5, $a5
; IPU1_2-NEXT:    f32div $a1, $a1, $a7
; IPU1_2-NEXT:    f32div $a0, $a0, $a6
; IPU1_2-NEXT:    f32v2tof16 $a0, $a0:1
; IPU1_2-NEXT:    f32div $a3, $a5, $a3
; IPU1_2-NEXT:    f32div $a2, $a4, $a2
; IPU1_2-NEXT:    f32v2tof16 $a1, $a2:3
; IPU1_2-NEXT:    ld64 $a6:7, $m11, $m15, 0 # 8-byte Folded Reload
; IPU1_2-NEXT:    add $m11, $m11, 8
; IPU1_2-NEXT:    .cfi_def_cfa_offset 0
; IPU1_2-NEXT:    br $m10

  %res = call <4 x half> @llvm.experimental.constrained.fdiv.v4f16(<4 x half> %x, <4 x half> %y, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

declare half @llvm.exp.f16(half %x)
define half @test_exp_f16(half %x) {
; CHECK-LABEL: test_exp_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a0, $a0, $a0
; CHECK-NEXT:    f16v2exp $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.exp.f16(half %x)
  ret half %res
}

declare half @llvm.experimental.constrained.exp.f16(half, metadata, metadata)
define half @test_constrained_exp_f16(half %x) {
; CHECK-LABEL: test_constrained_exp_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a0, $a0, $a0
; CHECK-NEXT:    f16v2exp $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.exp.f16(half %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

declare float @llvm.exp.f32(float %x)
define float @test_exp_f32(float %x) {
; CHECK-LABEL: test_exp_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32exp $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.exp.f32(float %x)
  ret float %res
}

declare float @llvm.experimental.constrained.exp.f32(float, metadata, metadata)
define float @test_constrained_exp_f32(float %x) {
; CHECK-LABEL: test_constrained_exp_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32exp $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.exp.f32(float %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

declare <2 x half> @llvm.exp.v2f16(<2 x half> %x)
define <2 x half> @test_exp_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_exp_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2exp $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.exp.v2f16(<2 x half> %x)
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.exp.v2f16(<2 x half>, metadata, metadata)
define <2 x half> @test_constrained_exp_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_constrained_exp_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2exp $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.exp.v2f16(<2 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

declare <2 x float> @llvm.exp.v2f32(<2 x float> %x)
define <2 x float> @test_exp_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_exp_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32exp $a0, $a0
; CHECK-NEXT:    f32exp $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.exp.v2f32(<2 x float> %x)
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.exp.v2f32(<2 x float>, metadata, metadata)
define <2 x float> @test_constrained_exp_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_constrained_exp_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32exp $a0, $a0
; CHECK-NEXT:    f32exp $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.exp.v2f32(<2 x float> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

declare <4 x half> @llvm.exp.v4f16(<4 x half> %x)
define <4 x half> @test_exp_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_exp_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2exp $a0, $a0
; CHECK-NEXT:    f16v2exp $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.exp.v4f16(<4 x half> %x)
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.exp.v4f16(<4 x half>, metadata, metadata)
define <4 x half> @test_constrained_exp_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_constrained_exp_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2exp $a0, $a0
; CHECK-NEXT:    f16v2exp $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.exp.v4f16(<4 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

declare half @llvm.exp2.f16(half %x)
define half @test_exp2_f16(half %x) {
; CHECK-LABEL: test_exp2_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a0, $a0, $a0
; CHECK-NEXT:    f16v2exp2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.exp2.f16(half %x)
  ret half %res
}

declare half @llvm.experimental.constrained.exp2.f16(half, metadata, metadata)
define half @test_constrained_exp2_f16(half %x) {
; CHECK-LABEL: test_constrained_exp2_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a0, $a0, $a0
; CHECK-NEXT:    f16v2exp2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.exp2.f16(half %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

declare float @llvm.exp2.f32(float %x)
define float @test_exp2_f32(float %x) {
; CHECK-LABEL: test_exp2_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32exp2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.exp2.f32(float %x)
  ret float %res
}

declare float @llvm.experimental.constrained.exp2.f32(float, metadata, metadata)
define float @test_constrained_exp2_f32(float %x) {
; CHECK-LABEL: test_constrained_exp2_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32exp2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.exp2.f32(float %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

declare <2 x half> @llvm.exp2.v2f16(<2 x half> %x)
define <2 x half> @test_exp2_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_exp2_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2exp2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.exp2.v2f16(<2 x half> %x)
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.exp2.v2f16(<2 x half>, metadata, metadata)
define <2 x half> @test_constrained_exp2_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_constrained_exp2_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2exp2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.exp2.v2f16(<2 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

declare <2 x float> @llvm.exp2.v2f32(<2 x float> %x)
define <2 x float> @test_exp2_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_exp2_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32exp2 $a0, $a0
; CHECK-NEXT:    f32exp2 $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.exp2.v2f32(<2 x float> %x)
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.exp2.v2f32(<2 x float>, metadata, metadata)
define <2 x float> @test_constrained_exp2_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_constrained_exp2_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32exp2 $a0, $a0
; CHECK-NEXT:    f32exp2 $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.exp2.v2f32(<2 x float> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

declare <4 x half> @llvm.exp2.v4f16(<4 x half> %x)
define <4 x half> @test_exp2_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_exp2_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2exp2 $a0, $a0
; CHECK-NEXT:    f16v2exp2 $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.exp2.v4f16(<4 x half> %x)
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.exp2.v4f16(<4 x half>, metadata, metadata)
define <4 x half> @test_constrained_exp2_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_constrained_exp2_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2exp2 $a0, $a0
; CHECK-NEXT:    f16v2exp2 $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.exp2.v4f16(<4 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

declare half @llvm.fmuladd.f16(half, half, half)
define half @test_fmuladd_f16(half %x, half %y, half %z) {
; CHECK-LABEL: test_fmuladd_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a1, $a1, $a1
; CHECK-NEXT:    f16v2mul $a0, $a0:BL, $a1
; CHECK-NEXT:    sort4x16lo $a1, $a2, $a2
; CHECK-NEXT:    f16v2add $a0, $a0:BL, $a1
; CHECK-NEXT:    br $m10
  %res = call half @llvm.fmuladd.f16(half %x, half %y, half %z)
  ret half %res
}

declare half @llvm.experimental.constrained.fmuladd.f16(half, half, half, metadata, metadata)
define half @test_constrained_fmuladd_f16(half %x, half %y, half %z) {
; CHECK-LABEL: test_constrained_fmuladd_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a1, $a1, $a1
; CHECK-NEXT:    f16v2mul $a0, $a0:BL, $a1
; CHECK-NEXT:    sort4x16lo $a1, $a2, $a2
; CHECK-NEXT:    f16v2add $a0, $a0:BL, $a1
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.fmuladd.f16(half %x, half %y, half %z, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

declare float @llvm.fmuladd.f32(float, float, float)
define float @test_fmuladd_f32(float %x, float %y, float %z) {
; CHECK-LABEL: test_fmuladd_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32mul $a0, $a0, $a1
; CHECK-NEXT:    f32add $a0, $a0, $a2
; CHECK-NEXT:    br $m10
  %res = call float @llvm.fmuladd.f32(float %x, float %y, float %z)
  ret float %res
}

declare float @llvm.experimental.constrained.fmuladd.f32(float, float, float, metadata, metadata)
define float @test_constrained_fmuladd_f32(float %x, float %y, float %z) {
; CHECK-LABEL: test_constrained_fmuladd_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32mul $a0, $a0, $a1
; CHECK-NEXT:    f32add $a0, $a0, $a2
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.fmuladd.f32(float %x, float %y, float %z, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

declare <2 x half> @llvm.fmuladd.v2f16(<2 x half>, <2 x half>, <2 x half>)
define <2 x half> @test_fmuladd_v2f16(<2 x half> %x, <2 x half> %y, <2 x half> %z) {
; CHECK-LABEL: test_fmuladd_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2mul $a0, $a0, $a1
; CHECK-NEXT:    f16v2add $a0, $a0, $a2
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.fmuladd.v2f16(<2 x half> %x, <2 x half> %y, <2 x half> %z)
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.fmuladd.v2f16(<2 x half>, <2 x half>, <2 x half>, metadata, metadata)
define <2 x half> @test_constrained_fmuladd_v2f16(<2 x half> %x, <2 x half> %y, <2 x half> %z) {
; CHECK-LABEL: test_constrained_fmuladd_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2mul $a0, $a0, $a1
; CHECK-NEXT:    f16v2add $a0, $a0, $a2
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.fmuladd.v2f16(<2 x half> %x, <2 x half> %y, <2 x half> %z, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

declare <2 x float> @llvm.fmuladd.v2f32(<2 x float>, <2 x float>, <2 x float>)
define <2 x float> @test_fmuladd_v2f32(<2 x float> %x, <2 x float> %y, <2 x float> %z) {
; CHECK-LABEL: test_fmuladd_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32v2mul $a0:1, $a0:1, $a2:3
; CHECK-NEXT:    f32v2add $a0:1, $a0:1, $a4:5
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.fmuladd.v2f32(<2 x float> %x, <2 x float> %y, <2 x float> %z)
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.fmuladd.v2f32(<2 x float>, <2 x float>, <2 x float>, metadata, metadata)
define <2 x float> @test_constrained_fmuladd_v2f32(<2 x float> %x, <2 x float> %y, <2 x float> %z) {
; CHECK-LABEL: test_constrained_fmuladd_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32v2mul $a0:1, $a0:1, $a2:3
; CHECK-NEXT:    f32v2add $a0:1, $a0:1, $a4:5
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.fmuladd.v2f32(<2 x float> %x, <2 x float> %y, <2 x float> %z, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

declare <4 x half> @llvm.fmuladd.v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z)
define <4 x half> @test_fmuladd_v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z) {
; CHECK-LABEL: test_fmuladd_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v4mul $a0:1, $a0:1, $a2:3
; CHECK-NEXT:    f16v4add $a0:1, $a0:1, $a4:5
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.fmuladd.v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z)
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.fmuladd.v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z, metadata, metadata)
define <4 x half> @test_constrained_fmuladd_v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z) {
; CHECK-LABEL: test_constrained_fmuladd_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v4mul $a0:1, $a0:1, $a2:3
; CHECK-NEXT:    f16v4add $a0:1, $a0:1, $a4:5
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.fmuladd.v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

declare half @llvm.fma.f16(half %x, half %y, half %z)
define half @test_fma_f16(half %x, half %y, half %z) {
; CHECK-LABEL: test_fma_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_fma
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.fma.f16(half %x, half %y, half %z)
  ret half %res
}

declare half @llvm.experimental.constrained.fma.f16(half, half, half, metadata, metadata)
define half @test_constrained_fma_f16(half %x, half %y, half %z) {
; CHECK-LABEL: test_constrained_fma_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_fma
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.fma.f16(half %x, half %y, half %z, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

declare float @llvm.fma.f32(float %x, float %y, float %z)
define float @test_fma_f32(float %x, float %y, float %z) {
; CHECK-LABEL: test_fma_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, fmaf
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.fma.f32(float %x, float %y, float %z)
  ret float %res
}

declare float @llvm.experimental.constrained.fma.f32(float, float, float, metadata, metadata)
define float @test_constrained_fma_f32(float %x, float %y, float %z) {
; CHECK-LABEL: test_constrained_fma_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, fmaf
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.fma.f32(float %x, float %y, float %z, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

declare <2 x half> @llvm.fma.v2f16(<2 x half> %x, <2 x half> %y, <2 x half> %z)
define <2 x half> @test_fma_v2f16(<2 x half> %x, <2 x half> %y, <2 x half> %z) {
; CHECK-LABEL: test_fma_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half2_fma
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.fma.v2f16(<2 x half> %x, <2 x half> %y, <2 x half> %z)
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.fma.v2f16(<2 x half>, <2 x half>, <2 x half>, metadata, metadata)
define <2 x half> @test_constrained_fma_v2f16(<2 x half> %x, <2 x half> %y, <2 x half> %z) {
; CHECK-LABEL: test_constrained_fma_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half2_fma
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.fma.v2f16(<2 x half> %x, <2 x half> %y, <2 x half> %z, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

declare <2 x float> @llvm.fma.v2f32(<2 x float> %x, <2 x float> %y, <2 x float> %z)
define <2 x float> @test_fma_v2f32(<2 x float> %x, <2 x float> %y, <2 x float> %z) {
; CHECK-LABEL: test_fma_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_fma
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.fma.v2f32(<2 x float> %x, <2 x float> %y, <2 x float> %z)
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.fma.v2f32(<2 x float>, <2 x float>, <2 x float>, metadata, metadata)
define <2 x float> @test_constrained_fma_v2f32(<2 x float> %x, <2 x float> %y, <2 x float> %z) {
; CHECK-LABEL: test_constrained_fma_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_fma
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.fma.v2f32(<2 x float> %x, <2 x float> %y, <2 x float> %z, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

declare <4 x half> @llvm.fma.v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z)
define <4 x half> @test_fma_v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z) {
; CHECK-LABEL: test_fma_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_fma
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.fma.v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z)
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.fma.v4f16(<4 x half>, <4 x half>, <4 x half>, metadata, metadata)
define <4 x half> @test_constrained_fma_v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z) {
; CHECK-LABEL: test_constrained_fma_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_fma
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.fma.v4f16(<4 x half> %x, <4 x half> %y, <4 x half> %z, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

declare half @llvm.log.f16(half %x)
define half @test_log_f16(half %x) {
; CHECK-LABEL: test_log_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a0, $a0, $a0
; CHECK-NEXT:    f16v2ln $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.log.f16(half %x)
  ret half %res
}

declare half @llvm.experimental.constrained.log.f16(half, metadata, metadata)
define half @test_constrained_log_f16(half %x) {
; CHECK-LABEL: test_constrained_log_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a0, $a0, $a0
; CHECK-NEXT:    f16v2ln $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.log.f16(half %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

declare float @llvm.log.f32(float %x)
define float @test_log_f32(float %x) {
; CHECK-LABEL: test_log_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32ln $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.log.f32(float %x)
  ret float %res
}

declare float @llvm.experimental.constrained.log.f32(float, metadata, metadata)
define float @test_constrained_log_f32(float %x) {
; CHECK-LABEL: test_constrained_log_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32ln $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.log.f32(float %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

declare <2 x half> @llvm.log.v2f16(<2 x half> %x)
define <2 x half> @test_log_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_log_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2ln $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.log.v2f16(<2 x half> %x)
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.log.v2f16(<2 x half>, metadata, metadata)
define <2 x half> @test_constrained_log_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_constrained_log_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2ln $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.log.v2f16(<2 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

declare <2 x float> @llvm.log.v2f32(<2 x float> %x)
define <2 x float> @test_log_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_log_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32ln $a0, $a0
; CHECK-NEXT:    f32ln $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.log.v2f32(<2 x float> %x)
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.log.v2f32(<2 x float>, metadata, metadata)
define <2 x float> @test_constrained_log_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_constrained_log_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32ln $a0, $a0
; CHECK-NEXT:    f32ln $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.log.v2f32(<2 x float> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

declare <4 x half> @llvm.log.v4f16(<4 x half> %x)
define <4 x half> @test_log_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_log_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2ln $a0, $a0
; CHECK-NEXT:    f16v2ln $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.log.v4f16(<4 x half> %x)
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.log.v4f16(<4 x half>, metadata, metadata)
define <4 x half> @test_constrained_log_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_constrained_log_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2ln $a0, $a0
; CHECK-NEXT:    f16v2ln $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.log.v4f16(<4 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

declare half @llvm.log10.f16(half %x)
define half @test_log10_f16(half %x) {
; CHECK-LABEL: test_log10_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_log10
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.log10.f16(half %x)
  ret half %res
}

declare half @llvm.experimental.constrained.log10.f16(half, metadata, metadata)
define half @test_constrained_log10_f16(half %x) {
; CHECK-LABEL: test_constrained_log10_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_log10
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.log10.f16(half %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

declare float @llvm.log10.f32(float %x)
define float @test_log10_f32(float %x) {
; CHECK-LABEL: test_log10_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, log10f
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.log10.f32(float %x)
  ret float %res
}

declare float @llvm.experimental.constrained.log10.f32(float, metadata, metadata)
define float @test_constrained_log10_f32(float %x) {
; CHECK-LABEL: test_constrained_log10_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, log10f
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.log10.f32(float %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

declare <2 x half> @llvm.log10.v2f16(<2 x half> %x)
define <2 x half> @test_log10_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_log10_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half2_log10
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.log10.v2f16(<2 x half> %x)
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.log10.v2f16(<2 x half>, metadata, metadata)
define <2 x half> @test_constrained_log10_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_constrained_log10_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half2_log10
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.log10.v2f16(<2 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

declare <2 x float> @llvm.log10.v2f32(<2 x float> %x)
define <2 x float> @test_log10_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_log10_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_log10
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.log10.v2f32(<2 x float> %x)
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.log10.v2f32(<2 x float>, metadata, metadata)
define <2 x float> @test_constrained_log10_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_constrained_log10_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_log10
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.log10.v2f32(<2 x float> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

declare <4 x half> @llvm.log10.v4f16(<4 x half> %x)
define <4 x half> @test_log10_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_log10_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_log10
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.log10.v4f16(<4 x half> %x)
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.log10.v4f16(<4 x half>, metadata, metadata)
define <4 x half> @test_constrained_log10_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_constrained_log10_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_log10
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.log10.v4f16(<4 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

declare half @llvm.log2.f16(half %x)
define half @test_log2_f16(half %x) {
; CHECK-LABEL: test_log2_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a0, $a0, $a0
; CHECK-NEXT:    f16v2log2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.log2.f16(half %x)
  ret half %res
}

declare half @llvm.experimental.constrained.log2.f16(half, metadata, metadata)
define half @test_constrained_log2_f16(half %x) {
; CHECK-LABEL: test_constrained_log2_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a0, $a0, $a0
; CHECK-NEXT:    f16v2log2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.log2.f16(half %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

declare float @llvm.log2.f32(float %x)
define float @test_log2_f32(float %x) {
; CHECK-LABEL: test_log2_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32log2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.log2.f32(float %x)
  ret float %res
}

declare float @llvm.experimental.constrained.log2.f32(float, metadata, metadata)
define float @test_constrained_log2_f32(float %x) {
; CHECK-LABEL: test_constrained_log2_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32log2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.log2.f32(float %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

declare <2 x half> @llvm.log2.v2f16(<2 x half> %x)
define <2 x half> @test_log2_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_log2_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2log2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.log2.v2f16(<2 x half> %x)
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.log2.v2f16(<2 x half>, metadata, metadata)
define <2 x half> @test_constrained_log2_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_constrained_log2_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2log2 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.log2.v2f16(<2 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

declare <2 x float> @llvm.log2.v2f32(<2 x float> %x)
define <2 x float> @test_log2_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_log2_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32log2 $a0, $a0
; CHECK-NEXT:    f32log2 $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.log2.v2f32(<2 x float> %x)
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.log2.v2f32(<2 x float>, metadata, metadata)
define <2 x float> @test_constrained_log2_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_constrained_log2_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32log2 $a0, $a0
; CHECK-NEXT:    f32log2 $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.log2.v2f32(<2 x float> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

declare <4 x half> @llvm.log2.v4f16(<4 x half> %x)
define <4 x half> @test_log2_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_log2_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2log2 $a0, $a0
; CHECK-NEXT:    f16v2log2 $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.log2.v4f16(<4 x half> %x)
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.log2.v4f16(<4 x half>, metadata, metadata)
define <4 x half> @test_constrained_log2_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_constrained_log2_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2log2 $a0, $a0
; CHECK-NEXT:    f16v2log2 $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.log2.v4f16(<4 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

define half @test_mod_f16(half %x, half %y) {
; CHECK-LABEL: test_mod_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_fmod
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = frem half %x, %y
  ret half %res
}

declare half @llvm.experimental.constrained.frem.f16(half, half, metadata, metadata)
define half @test_strict_mod_f16(half %x, half %y) {
; CHECK-LABEL: test_strict_mod_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_fmod
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.frem.f16(half %x, half %y, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

define float @test_mod_f32(float %x, float %y) {
; CHECK-LABEL: test_mod_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, fmodf
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = frem float %x, %y
  ret float %res
}

declare float @llvm.experimental.constrained.frem.f32(float, float, metadata, metadata)
define float @test_strict_mod_f32(float %x, float %y) {
; CHECK-LABEL: test_strict_mod_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, fmodf
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.frem.f32(float %x, float %y, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

define <2 x half> @test_mod_v2f16(<2 x half> %x, <2 x half> %y) {
; CHECK-LABEL: test_mod_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half2_fmod
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = frem <2 x half> %x, %y
  ret <2 x half> %res
}

define <2 x float> @test_mod_v2f32(<2 x float> %x, <2 x float> %y) {
; CHECK-LABEL: test_mod_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_fmod
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = frem <2 x float> %x, %y
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.frem.v2f32(<2 x float>, <2 x float>, metadata, metadata)
define <2 x float> @test_strict_mod_v2f32(<2 x float> %x, <2 x float> %y) {
; CHECK-LABEL: test_strict_mod_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_fmod
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.frem.v2f32(<2 x float> %x, <2 x float> %y, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

define <4 x half> @test_mod_v4f16(<4 x half> %x, <4 x half> %y) {
; CHECK-LABEL: test_mod_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_fmod
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = frem <4 x half> %x, %y
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.frem.v4f16(<4 x half>, <4 x half>, metadata, metadata)
define <4 x half> @test_strict_mod_v4f16(<4 x half> %x, <4 x half> %y) {
; CHECK-LABEL: test_strict_mod_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_fmod
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.frem.v4f16(<4 x half> %x, <4 x half> %y, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

declare half @llvm.pow.f16(half %x, half %y)
define half @test_pow_f16(half %x, half %y) {
; CHECK-LABEL: test_pow_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_pow
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.pow.f16(half %x, half %y)
  ret half %res
}

declare float @llvm.pow.f32(float %x, float %y)
define float @test_pow_f32(float %x, float %y) {
; CHECK-LABEL: test_pow_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, powf
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.pow.f32(float %x, float %y)
  ret float %res
}

declare <2 x half> @llvm.pow.v2f16(<2 x half> %x, <2 x half> %y)
define <2 x half> @test_pow_v2f16(<2 x half> %x, <2 x half> %y) {
; CHECK-LABEL: test_pow_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half2_pow
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.pow.v2f16(<2 x half> %x, <2 x half> %y)
  ret <2 x half> %res
}

declare <2 x float> @llvm.pow.v2f32(<2 x float> %x, <2 x float> %y)
define <2 x float> @test_pow_v2f32(<2 x float> %x, <2 x float> %y) {
; CHECK-LABEL: test_pow_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_pow
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.pow.v2f32(<2 x float> %x, <2 x float> %y)
  ret <2 x float> %res
}

declare <4 x half> @llvm.pow.v4f16(<4 x half> %x, <4 x half> %y)
define <4 x half> @test_pow_v4f16(<4 x half> %x, <4 x half> %y) {
; CHECK-LABEL: test_pow_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_pow
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.pow.v4f16(<4 x half> %x, <4 x half> %y)
  ret <4 x half> %res
}

declare half @llvm.sin.f16(half %x)
define half @test_sin_f16(half %x) {
; CHECK-LABEL: test_sin_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_sin
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.sin.f16(half %x)
  ret half %res
}

declare half @llvm.experimental.constrained.sin.f16(half, metadata, metadata)
define half @test_constrained_sin_f16(half %x) {
; CHECK-LABEL: test_constrained_sin_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half_sin
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.sin.f16(half %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

declare float @llvm.sin.f32(float %x)
define float @test_sin_f32(float %x) {
; CHECK-LABEL: test_sin_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, sinf
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.sin.f32(float %x)
  ret float %res
}

declare float @llvm.experimental.constrained.sin.f32(float, metadata, metadata)
define float @test_constrained_sin_f32(float %x) {
; CHECK-LABEL: test_constrained_sin_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, sinf
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.sin.f32(float %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

declare <2 x half> @llvm.sin.v2f16(<2 x half> %x)
define <2 x half> @test_sin_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_sin_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half2_sin
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.sin.v2f16(<2 x half> %x)
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.sin.v2f16(<2 x half>, metadata, metadata)
define <2 x half> @test_constrained_sin_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_constrained_sin_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half2_sin
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.sin.v2f16(<2 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

declare <2 x float> @llvm.sin.v2f32(<2 x float> %x)
define <2 x float> @test_sin_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_sin_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_sin
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.sin.v2f32(<2 x float> %x)
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.sin.v2f32(<2 x float>, metadata, metadata)
define <2 x float> @test_constrained_sin_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_constrained_sin_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, float2_sin
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.sin.v2f32(<2 x float> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

declare <4 x half> @llvm.sin.v4f16(<4 x half> %x)
define <4 x half> @test_sin_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_sin_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_sin
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.sin.v4f16(<4 x half> %x)
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.sin.v4f16(<4 x half>, metadata, metadata)
define <4 x half> @test_constrained_sin_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_constrained_sin_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, half4_sin
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.sin.v4f16(<4 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

declare half @llvm.sqrt.f16(half %x)
define half @test_sqrt_f16(half %x) {
; CHECK-LABEL: test_sqrt_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16tof32 $a0, $a0
; CHECK-NEXT:    f32sqrt $a0, $a0
; CHECK-NEXT:    f32tof16 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.sqrt.f16(half %x)
  ret half %res
}

declare half @llvm.experimental.constrained.sqrt.f16(half, metadata, metadata)
define half @test_strict_sqrt_f16(half %x) {
; CHECK-LABEL: test_strict_sqrt_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16tof32 $a0, $a0
; CHECK-NEXT:    f32sqrt $a0, $a0
; CHECK-NEXT:    f32tof16 $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.experimental.constrained.sqrt.f16(half %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret half %res
}

declare float @llvm.sqrt.f32(float %x)
define float @test_sqrt_f32(float %x) {
; CHECK-LABEL: test_sqrt_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32sqrt $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.sqrt.f32(float %x)
  ret float %res
}

declare float @llvm.experimental.constrained.sqrt.f32(float, metadata, metadata)
define float @test_strict_sqrt_f32(float %x) {
; CHECK-LABEL: test_strict_sqrt_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32sqrt $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.experimental.constrained.sqrt.f32(float %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret float %res
}

declare <2 x half> @llvm.sqrt.v2f16(<2 x half> %x)
define <2 x half> @test_sqrt_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_sqrt_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2tof32 $a0:1, $a0
; CHECK-NEXT:    f32sqrt $a0, $a0
; CHECK-NEXT:    f32sqrt $a1, $a1
; CHECK-NEXT:    f32v2tof16 $a0, $a0:1
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.sqrt.v2f16(<2 x half> %x)
  ret <2 x half> %res
}

declare <2 x half> @llvm.experimental.constrained.sqrt.v2f16(<2 x half>, metadata, metadata)
define <2 x half> @test_strict_sqrt_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_strict_sqrt_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2tof32 $a0:1, $a0
; CHECK-NEXT:    f32sqrt $a0, $a0
; CHECK-NEXT:    f32sqrt $a1, $a1
; CHECK-NEXT:    f32v2tof16 $a0, $a0:1
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.experimental.constrained.sqrt.v2f16(<2 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x half> %res
}

declare <2 x float> @llvm.sqrt.v2f32(<2 x float> %x)
define <2 x float> @test_sqrt_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_sqrt_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32sqrt $a0, $a0
; CHECK-NEXT:    f32sqrt $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.sqrt.v2f32(<2 x float> %x)
  ret <2 x float> %res
}

declare <2 x float> @llvm.experimental.constrained.sqrt.v2f32(<2 x float>, metadata, metadata)
define <2 x float> @test_strict_sqrt_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_strict_sqrt_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32sqrt $a0, $a0
; CHECK-NEXT:    f32sqrt $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.experimental.constrained.sqrt.v2f32(<2 x float> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <2 x float> %res
}

declare <4 x half> @llvm.sqrt.v4f16(<4 x half> %x)
define <4 x half> @test_sqrt_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_sqrt_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2tof32 $a2:3, $a0
; CHECK-NEXT:    f32sqrt $a2, $a2
; CHECK-NEXT:    f32sqrt $a3, $a3
; CHECK-NEXT:    f32v2tof16 $a0, $a2:3
; CHECK-NEXT:    f16v2tof32 $a2:3, $a1
; CHECK-NEXT:    f32sqrt $a2, $a2
; CHECK-NEXT:    f32sqrt $a3, $a3
; CHECK-NEXT:    f32v2tof16 $a1, $a2:3
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.sqrt.v4f16(<4 x half> %x)
  ret <4 x half> %res
}

declare <4 x half> @llvm.experimental.constrained.sqrt.v4f16(<4 x half>, metadata, metadata)
define <4 x half> @test_strict_sqrt_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_strict_sqrt_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2tof32 $a2:3, $a0
; CHECK-NEXT:    f32sqrt $a2, $a2
; CHECK-NEXT:    f32sqrt $a3, $a3
; CHECK-NEXT:    f32v2tof16 $a0, $a2:3
; CHECK-NEXT:    f16v2tof32 $a2:3, $a1
; CHECK-NEXT:    f32sqrt $a2, $a2
; CHECK-NEXT:    f32sqrt $a3, $a3
; CHECK-NEXT:    f32v2tof16 $a1, $a2:3
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.experimental.constrained.sqrt.v4f16(<4 x half> %x, metadata !"round.tonearest", metadata !"fpexcept.strict")
  ret <4 x half> %res
}

declare half @llvm.colossus.tanh.f16(half %x)
define half @test_tanh_f16(half %x) {
; CHECK-LABEL: test_tanh_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sort4x16lo $a0, $a0, $a0
; CHECK-NEXT:    f16v2tanh $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call half @llvm.colossus.tanh.f16(half %x)
  ret half %res
}

declare float @llvm.colossus.tanh.f32(float %x)
define float @test_tanh_f32(float %x) {
; CHECK-LABEL: test_tanh_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32tanh $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call float @llvm.colossus.tanh.f32(float %x)
  ret float %res
}

declare <2 x half> @llvm.colossus.tanh.v2f16(<2 x half> %x)
define <2 x half> @test_tanh_v2f16(<2 x half> %x) {
; CHECK-LABEL: test_tanh_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2tanh $a0, $a0
; CHECK-NEXT:    br $m10
  %res = call <2 x half> @llvm.colossus.tanh.v2f16(<2 x half> %x)
  ret <2 x half> %res
}

declare <2 x float> @llvm.colossus.tanh.v2f32(<2 x float> %x)
define <2 x float> @test_tanh_v2f32(<2 x float> %x) {
; CHECK-LABEL: test_tanh_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f32tanh $a0, $a0
; CHECK-NEXT:    f32tanh $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <2 x float> @llvm.colossus.tanh.v2f32(<2 x float> %x)
  ret <2 x float> %res
}

declare <4 x half> @llvm.colossus.tanh.v4f16(<4 x half> %x)
define <4 x half> @test_tanh_v4f16(<4 x half> %x) {
; CHECK-LABEL: test_tanh_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    f16v2tanh $a0, $a0
; CHECK-NEXT:    f16v2tanh $a1, $a1
; CHECK-NEXT:    br $m10
  %res = call <4 x half> @llvm.colossus.tanh.v4f16(<4 x half> %x)
  ret <4 x half> %res
}
