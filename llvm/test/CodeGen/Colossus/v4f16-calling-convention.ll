; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --remove_checks
; RUN: llc < %s  -mtriple=colossus -mattr=+ipu1 | FileCheck %s -check-prefixes=CHECK,IPU1
; RUN: llc < %s -mtriple=colossus -mattr=+ipu2 | FileCheck %s -check-prefixes=CHECK,IPU2

define void @callee_reg_args(<4 x half> %a, <4 x half> %b) {
; CHECK-LABEL: callee_reg_args:
; CHECK:       # %bb.0:
; CHECK-NEXT:    #APP
; CHECK-NEXT:    urand64 $a0:1
; CHECK-NEXT:    urand64 $a2:3
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    br $m10
  call void asm sideeffect "urand64 $0\0a\09urand64 $1", "r,r"(<4 x half> %a, <4 x half> %b)
  ret void
}

define void @callee_stack_arg(float %a, float %a1, float %a2, float %a3, <4 x half> %b, <4 x half> %c) {
; IPU1-LABEL: callee_stack_arg:
; IPU1:       # %bb.0:
; IPU1-NEXT:    add $m11, $m11, -8
; IPU1-NEXT:    .cfi_def_cfa_offset 8
; IPU1-NEXT:    .cfi_offset $a6:7, -8
; IPU1-NEXT:    st64 $a6:7, $m11, $m15, 0 # 8-byte Folded Spill
; IPU1-NEXT:    ld64 $a6:7, $m11, $m15, 1
; IPU1-NEXT:    #APP
; IPU1-NEXT:    andc $a0, $a1, $a2
; IPU1-NEXT:    urand32 $a3
; IPU1-NEXT:    urand64 $a4:5
; IPU1-NEXT:    urand64 $a6:7
; IPU1-NEXT:    #NO_APP
; IPU1-NEXT:    ld64 $a6:7, $m11, $m15, 0 # 8-byte Folded Reload
; IPU1-NEXT:    add $m11, $m11, 8
; IPU1-NEXT:    .cfi_def_cfa_offset 0
; IPU1-NEXT:    br $m10
;
; IPU2-LABEL: callee_stack_arg:
; IPU2:       # %bb.0:
; IPU2-NEXT:    add $m11, $m11, -8
; IPU2-NEXT:    .cfi_def_cfa_offset 8
; IPU2-NEXT:    .cfi_offset $a6:7, -8
; IPU2-NEXT:    st64 $a6:7, $m11, $m15, 0 # 8-byte Folded Spill
; IPU2-NEXT:    ld64 $a6:7, $m11, $m15, 1
; IPU2-NEXT:    #APP
; IPU2-NEXT:    andc $a0, $a1, $a2
; IPU2-NEXT:    urand32 $a3
; IPU2-NEXT:    urand64 $a4:5
; IPU2-NEXT:    urand64 $a6:7
; IPU2-NEXT:    #NO_APP
; IPU2-NEXT:    ld64 $a6:7, $m11, $m15, 0 # 8-byte Folded Reload
; IPU2-NEXT:    add $m11, $m11, 8
; IPU2-NEXT:    .cfi_def_cfa_offset 0
; IPU2-NEXT:    br $m10

  call void asm sideeffect "andc $0, $1, $2\0a\09urand32 $3\0a\09urand64 $4\0a\09urand64 $5", "r,r,r,r,r,r"(float %a,
                                                          float %a1,
                                                          float %a2,
                                                          float %a3,
                                                          <4 x half> %b,
                                                          <4 x half> %c)
  ret void
}

define <4 x half> @callee_return(<4 x half> %a) {
; CHECK-LABEL: callee_return:
; CHECK:       # %bb.0:
; CHECK-NEXT:    #APP
; CHECK-NEXT:    urand64 $a0:1
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    br $m10
  call void asm sideeffect "urand64 $0", "r"(<4 x half> %a)
  ret <4 x half> %a
}

define void @caller_reg_args(<4 x half> %a, <4 x half> %b) {
; CHECK-LABEL: caller_reg_args:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add $m11, $m11, -8
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    .cfi_offset $m10, -4
; CHECK-NEXT:    st32 $m10, $m11, $m15, 1 # 4-byte Folded Spill
; CHECK-NEXT:    call $m10, callee_reg_args
; CHECK-NEXT:    ld32 $m10, $m11, $m15, 1 # 4-byte Folded Reload
; CHECK-NEXT:    add $m11, $m11, 8
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    br $m10
  call void @callee_reg_args(<4 x half> %a, <4 x half> %b)
  ret void
}

define void @caller_stack_arg(float %a, float %a1, float %a2, float %a3, <4 x half> %b, <4 x half> %c) {
; IPU1-LABEL: caller_stack_arg:
; IPU1:       # %bb.0:
; IPU1-NEXT:    add $m11, $m11, -24
; IPU1-NEXT:    .cfi_def_cfa_offset 24
; IPU1-NEXT:    .cfi_offset $m10, -4
; IPU1-NEXT:    .cfi_offset $a6:7, -16
; IPU1-NEXT:    st32 $m10, $m11, $m15, 5 # 4-byte Folded Spill
; IPU1-NEXT:    st64 $a6:7, $m11, $m15, 1 # 8-byte Folded Spill
; IPU1-NEXT:    ld64 $a6:7, $m11, $m15, 3
; IPU1-NEXT:    st64 $a6:7, $m11, $m15, 0
; IPU1-NEXT:    call $m10, callee_stack_arg
; IPU1-NEXT:    ld64 $a6:7, $m11, $m15, 1 # 8-byte Folded Reload
; IPU1-NEXT:    ld32 $m10, $m11, $m15, 5 # 4-byte Folded Reload
; IPU1-NEXT:    add $m11, $m11, 24
; IPU1-NEXT:    .cfi_def_cfa_offset 0
; IPU1-NEXT:    br $m10
;
; IPU2-LABEL: caller_stack_arg:
; IPU2:       # %bb.0:
; IPU2-NEXT:    add $m11, $m11, -24
; IPU2-NEXT:    .cfi_def_cfa_offset 24
; IPU2-NEXT:    .cfi_offset $m10, -4
; IPU2-NEXT:    .cfi_offset $a6:7, -16
; IPU2-NEXT:    st32 $m10, $m11, $m15, 5 # 4-byte Folded Spill
; IPU2-NEXT:    st64 $a6:7, $m11, $m15, 1 # 8-byte Folded Spill
; IPU2-NEXT:    ld64 $a6:7, $m11, $m15, 3
; IPU2-NEXT:    st64 $a6:7, $m11, $m15, 0
; IPU2-NEXT:    call $m10, callee_stack_arg
; IPU2-NEXT:    ld64 $a6:7, $m11, $m15, 1 # 8-byte Folded Reload
; IPU2-NEXT:    ld32 $m10, $m11, $m15, 5 # 4-byte Folded Reload
; IPU2-NEXT:    add $m11, $m11, 24
; IPU2-NEXT:    .cfi_def_cfa_offset 0
; IPU2-NEXT:    br $m10

  call void @callee_stack_arg(float %a, float %a1, float %a2, float %a3, <4 x half> %b, <4 x half> %c)
  ret void
}
